{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Case Study\n",
    "\n",
    "#### Author: Denis Pastory\n",
    "\n",
    "### MAP  AREA\n",
    "Dar-es-salaam, Tanzania, East Africa\n",
    "\n",
    "- [https://www.openstreetmap.org/search?query=dar%20es%20salaam#map=12/-6.8235/39.2695]\n",
    "\n",
    "Dar es Salaam is the former capital and largest city in Tanzania. It is one of the largest cities in East Africa by population. The region had a population of 4,364,541 as of the official 2012 census and the city is one of the fastest growing cities in the world. \n",
    "I would like to contribute to improvement on OpenstreetMap to help ease movement within the city and usage of several facilities in the city\n",
    "\n",
    "After downloading the map from openstreetmap. I saw several mistakes that i managed to solve in this analysis.\n",
    "The openstreet downloaded map was big so i had to first reduce it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PRELIMINARY ANALYSIS\n",
    "### 1.1. This code creates a sample data to be used in the analysis \n",
    "The original data was 1.3 GB so had to reduce it to about 70MB using the code below\n",
    "```python\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"dar_sample.osm\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"DAR.osm\" # The data to be used\n",
    "\n",
    "k = 2 # Parameter: take every k-th top level element\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-\n",
    "    file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "  # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')\n",
    "    ```  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Function to Check the tags in the sample file created\n",
    " After gettting the data to work with. There was need to check on the elements(more especially nodes,tag and way) to have a seens of what amount of data will deal with.\n",
    " ```python\n",
    "def count_tags_element(filename):\n",
    "    tags = defaultdict(int) # initate tags  in file\n",
    "    for event, element in ET.iterparse(filename): \n",
    "        tags[element.tag] += 1\n",
    "    return tags\n",
    "    \n",
    "    \n",
    "count_tags_element(\"DAR.osm\")\n",
    "\n",
    "defaultdict(int,\n",
    "              {'member': 637,\n",
    "             'nd': 382408,\n",
    "             'node': 329542,\n",
    "             'osm': 1,\n",
    "             'relation': 58,\n",
    "             'tag': 102113,\n",
    "             'way': 56882})\n",
    "             ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 This Checks for tag types in the data\n",
    "```python\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "lower_colon = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        if lower.search(element.attrib['k']):\n",
    "            keys['lower'] += 1\n",
    "        elif lower_colon.search(element.attrib['k']):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys['problemchars'] += 1\n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "    return keys\n",
    "\n",
    "def process_map_check(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "    \n",
    "process_map_check(\"DAR.osm\")\n",
    "```\n",
    "__{'lower': 69615, 'lower_colon': 32482, 'other': 16, 'problemchars': 0}__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Problems Related in the Map\n",
    "\n",
    "    I will discuss one of the major problem encourted in the data set.\n",
    "    The street names are not properly labeled. My main task was to clean the improper street names in the data sets. \n",
    "    Most of the streets were in node and way element.\n",
    "\n",
    "- Street names are not labeled 'street' in the tag \n",
    "    ```XML \n",
    "    <tag k=\"addr:street\" v=\"Almasi\" /> ```\n",
    "    \n",
    "    so for consistence we should expect something like this\n",
    " ```XML \n",
    "    <tag k=\"addr:street\" v=\"Almasi Street\" /> ```\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. AUDIT\n",
    " To tackle the above challenge. I had to do some DATA AUDITING using [audit_data.py](https://github.com/DenisDPR/Data-Analyst-Nano-Degree/blob/master/Project%202/OpenStreetMapData/audit_data.py) before processing the whole data to solve the problem.\n",
    "The process of auditing was done is four main parts and thus creating four functions.\n",
    "### 3.1 audit_street_type\n",
    "Using  [re](https://docs.python.org/2/library/re.html) package library. This enabled me to specifies a set of strings that match a particular string matches, and of which my target was   addr:street\n",
    "```python\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected_street_types:\n",
    "            street_types[street_type].add(street_name)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 is_street_name\n",
    "   This function suchs for element attributes whose 'K' key is equivalent to \"addr:street\"\n",
    " ```python\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 audit_street\n",
    "```python\n",
    "def audit_street(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 update_name\n",
    "This helped update the data for consistency as per the mapping and expected street types in the data set\n",
    "```python\n",
    "def update_name(name):\n",
    "    \"\"\"\n",
    "    For consistency, accuracy data is cleaned to be \n",
    "    used in SQL database\n",
    "    \"\"\"\n",
    "    if num_line_street_re.match(name):\n",
    "        nth = nth_re.search(name)\n",
    "        name = lane_mapping[nth.group(0)] + \" Line\"\n",
    "        return name\n",
    "    \n",
    "    elif name == \"Ahmed & Mohamed Line\" or name == \"Ahmed/Mohamed Line\":\n",
    "        name = \"Ahmed-Mohamed Line\"\n",
    "        return name\n",
    "\n",
    "    else:\n",
    "        original_name = name\n",
    "        for key in mapping.keys():\n",
    "            # When mapping key match such as \"St.\" \n",
    "            type_fix_name = re.sub(r'\\s' + re.escape(key) + r'$', ' ' + mapping[key], original_name)\n",
    "            nesw = nesw_re.search(type_fix_name)\n",
    "            if nesw is not None:\n",
    "                for key in street_mapping.keys():\n",
    "                    # No renaming proper names.\n",
    "                    dir_fix_name = re.sub(r'\\s' + re.escape(key) + re.escape(nesw.group(0)), \" \" + street_mapping[key] + nesw.group(0), type_fix_name)\n",
    "                    if dir_fix_name != type_fix_name:\n",
    "                        return dir_fix_name\n",
    "            if type_fix_name != original_name:\n",
    "                return type_fix_name\n",
    "    # Check for capitalized names such as street\n",
    "    last_word = original_name.rsplit(None, 1)[-1]\n",
    "    if last_word.islower():\n",
    "        original_name = re.sub(last_word, last_word.title(), original_name)\n",
    "    return original_name\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PROCESSING\n",
    "After auditing is complete the next step was to prepare the data to be inserted into a SQL database.Using __process_data.py__\n",
    "Parse the elements in the DAR.OSM XML file document format to tabular format such that they can be inserted into .csv files which will be ready to be inserted into SQL database using the given schema\n",
    "Validation of data is important so using cerberus library, the output can be validated against the schema. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The codes to determine file size\n",
    "```python\n",
    "import os\n",
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    this function will convert bytes to MB.... GB... etc\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "def file_size(file_path):\n",
    "    \"\"\"\n",
    "    this function will return the file size\n",
    "    \"\"\"\n",
    "    if os.path.isfile(file_path):\n",
    "        file_info = os.stat(file_path)\n",
    "        return convert_bytes(file_info.st_size)\n",
    "\n",
    "file_path = r\"DAR.osm\"\n",
    "print file_size(file_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### size of the file\n",
    "\n",
    "    DAR.osm  :  70.3 MB\n",
    "    nodes.csv  :  27.3 MB\n",
    "    nodes_tags.csv  :  265.3 KB\n",
    "    ways.csv  :  3.5 MB\n",
    "    ways_nodes.csv  :  8.8 MB\n",
    "    ways_tags.csv  :  3.1 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SQL \n",
    "\n",
    "## Data Overview and Additional ideas:\n",
    "\n",
    "### Number of nodes<br>\n",
    "    SELECT Count(*)FROM   nodes; \n",
    "     139480\n",
    "### Number of ways\n",
    "    SELECT Count(*) FROM ways;\n",
    "    41964\n",
    "### Number of users\n",
    "    SELECT COUNT(distinct(user.uid)) \n",
    "    FROM (SELECT uid \n",
    "            FROM nodes union all \n",
    "            SELECT uid FROM ways) user;\n",
    "    1279\n",
    "### Top 10 Most  Active users \n",
    "    SELECT e.user, COUNT(*) as num\n",
    "           FROM (SELECT user FROM Nodes UNION ALL SELECT user FROM Ways) e\n",
    "           GROUP BY e.user\n",
    "           ORDER BY num DESC\n",
    "           LIMIT 10;\n",
    "           \n",
    "    kombe1207,8258\n",
    "    amour_nyl, 4720\n",
    "    innocent maholi, 4697\n",
    "    Doricas Mgusi, 4427\n",
    "    Hawa Adinani, 4195\n",
    "    tonny john, 2999\n",
    "    Kabaka@1,2 170\n",
    "    mwanaharusi ngaluma\", 2132\n",
    "    elia dominic, 2069\n",
    "    Immaculate Mwanja, 2028\n",
    "## Religion\n",
    "    SELECT nodes_tags.value, COUNT(*) as num\n",
    "    FROM nodes_tags \n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='place_of_worship') i\n",
    "    ON nodes_tags.id=i.id\n",
    "    WHERE nodes_tags.key='religion'\n",
    "    GROUP BY nodes_tags.value\n",
    "    ORDER BY num DESC;\n",
    "    \n",
    "    christian|6\n",
    "    muslim|6\n",
    " With the figure above, since dar es salaam is along the coast, it is not a surprise to see such a number of 50% to 50% christian muslims. \n",
    "  [More information of religion distribution can be found here](https://en.wikipedia.org/wiki/Religion_in_Tanzania)\n",
    "    \n",
    "## Top most cuisine\n",
    "    SELECT nodes_tags.value, COUNT(*) as num\n",
    "        FROM nodes_tags \n",
    "        JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='restaurant') i\n",
    "        ON nodes_tags.id=i.id\n",
    "        WHERE nodes_tags.key='cuisine'\n",
    "        GROUP BY nodes_tags.value\n",
    "        ORDER BY num DESC;\n",
    "\n",
    "    burger,1\n",
    "    chicken;african;barbecue;grill,1\n",
    "    thai,1\n",
    "## Number of Highways with bus stop\n",
    "    SELECT COUNT(*) \n",
    "    FROM nodes_tags \n",
    "    WHERE key=\"highway\" and value = \"bus_stop\";\n",
    "    12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 5. Data Improvement and statistics\n",
    "Considering the query where \n",
    "\n",
    "#### Number of Highways\n",
    "    SELECT COUNT (*) \n",
    "    FROM nodes_tags \n",
    "    WHERE  key=\"highway\"; 16\n",
    "\n",
    "#### Number of Highways with traffic signals\n",
    "\n",
    "    SELECT  COUNT(*) from nodes_tags \n",
    "        WHERE key=\"highway\" \n",
    "        AND value = \"traffic_signals\"; 1\n",
    "The number of highways accounts for 6.25% of the highways. \n",
    "The number of highways with traffic signals seems to be proportional small compared with the <br>\n",
    "available highways. \n",
    "For most highways in Dar-es-salaam, as shown in image below, Pedestrians also use them. Having such a small number of traffic signals puts a high risk of many accidents. <br>\n",
    "However, there are quiet many traffic signals that are not included in the open street map. <br>\n",
    "The responsible personel ( Tanzania Roads Agency) should take come responsiblity to update the information.![Highway in Tanzania](https://github.com/DenisDPR/Data-Analyst-Nano-Degree/blob/master/Project%202/OpenStreetMapData/Kilwa%20Highway.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Ideas about data set\n",
    "\n",
    "As far as Tanzania is concerned and Dar es salaam in particular, Data is actually a big problem. The few available data some times is not used effective or it's importance is not recognized. \n",
    "\n",
    "During, my data analysis, I discovered alot of thing that need to be improved on. Tha case of __HIGH SIGNAL__  may be just one in a million. \n",
    "## Solution\n",
    "The Dar es salaam city and it's sub villages are under a Local government system. With the local government system, Most developments are under Local government Authority. This includes construction of roads, streets etc. The major constructions are infact mainly for public. \n",
    "Having a well established __INVENTORY__ of all infrastructures ( roads, hospitals etc) can be one of the lead solution. The information from the established inventory can be used to improve on openstreetmap.\n",
    "Many students ( with major in Geography, Computer etc) are some times attached to these Local government offices for there Field Practicals, so they can help in such tasks of data input for improving the openstreetmap of dar es salaam using the inventory.\n",
    "\n",
    "## Benefits\n",
    "Having a well established openstreetmap can be of benefit in a number of ways.I'll talk about;\n",
    "- Logistics. \n",
    "Dar es salaam has got poor logistics in terms of not well established house/building addresses. This means that delivery of goods to a specified address is insufficiently lacking, So when a city is properly addresses( street address properly labeled in openstreet map) then they can be used for logistics and transpotation purposes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The Dar es salaam OpenStreetMap dataset is quite a large map with alot of information lacking that needs improvement. \n",
    "For this project i managed to clean the streets however much data cleaning can be done for other messy information. using SQL, alot of important information can be drawn from the dataset. The Data wrangling process is not that easy more especially if one does have clear information for the data he/she is working on and also the area. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "   - [Udacity Discussion Forums](https://discussions.udacity.com/c/nd002-data-wrangling/nd002-p-wrangle-openstreetmaps-data-with-sql)\n",
    "   - (https://docs.python.org/2/library/re.html)\n",
    "   - (https://en.wikipedia.org/wiki/Religion_in_Tanzania)\n",
    "   - (https://docs.python.org/2/library/re.html)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
